<h1 align="center">ðŸš€ SwiftLet</h1>

<p align="center"><strong>SwiftLet is a lightweight Python framework for running open-source Large Language Models (LLMs) locally using <code>safetensors</code>.</strong></p>

<p>
Swiftlet have collection of different LLMs. Right now we only have implemented gemma1, gemma2 and gemma3. Gemma3 vision does not work. More models will be added to repo in future. This is only for learning reimplementation of LLMs and ML models.
</p>

<p>
This project is currently in its early stages and focuses on enabling direct local execution of LLMs. Future updates will expand its capabilities with support for advanced features such as tool integration, file interaction, and modular extensions to improve local LLM workflows.
</p>

## Planned Features

SwiftLet is under active development. The following features are planned for future releases:

- **Integration with Native Runtimes**  
  Support for running LLMs via optimized backends like `llama.cpp` for improved performance on local machines.

- **File Interaction Support**  
  Enable LLMs to read and process local documents, files, and structured data formats.

- **Modular Tool Integration**  
  Easily connect models to external tools, functions, or APIs to extend their utility.

- **Enhanced Model Management**  
  Tools to manage multiple models, switch between them, and handle custom configurations.

- **Prompt Templates and Inference APIs**  
  Built-in support for structured prompting, templates, and customizable inference pipelines.

- **Extensibility and Plugins**  
  A modular architecture that allows developers to add new capabilities with simple plugin hooks.

- **Performance Monitoring and Debugging**  
  Tools for logging, inspecting model behavior, and optimizing local performance.

---

## Codes
1. Gemma: <a href="https://www.kaggle.com/code/apibrains/gemma3-swiftlet">View on Kaggle</a>
